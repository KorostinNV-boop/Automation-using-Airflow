Построение витрин данных: Airflow + PySpark.

Цель проекта: Автоматизация подготовки данных для команды аналитики сервиса.

Задачи:

* Разработка PySpark-скрипта для обработки данных и создания витрин с агрегированными показателями по текстовому и аудиоконтенту.

* Оркестрация процесса с помощью Apache Airflow: создание DAG для запуска Spark-задачи из S3 и обновления итоговой таблицы в хранилище.

Результат: Витрины данных обновляются автоматически, что сокращает время подготовки отчетов и исключает ручной запуск обработки.
